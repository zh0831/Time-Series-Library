import os
import torch
import sys
import re
import glob
# å¼•å…¥æ­£ç¡®çš„ç±»å (å•æ•°å½¢å¼)
from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast

# =========================================================
#  1. è·¯å¾„ä¸ç¯å¢ƒé…ç½® (æ ¹æ®æ‚¨çš„ Shell è„šæœ¬ä¿®æ”¹)
# =========================================================

# ã€é‡è¦ã€‘Checkpoints çš„ç»å¯¹è·¯å¾„
# å‡è®¾ run.py åœ¨ /root/autodl-tmp/Time-Series-Library/
# é‚£ä¹ˆ checkpoints é€šå¸¸åœ¨ /root/autodl-tmp/Time-Series-Library/checkpoints/
CHECKPOINT_ROOT = '/root/autodl-tmp/Time-Series-Library/checkpoints/'

# ã€å¯¹åº”è„šæœ¬ã€‘root_path_name
DATA_ROOT_PATH = '/root/autodl-tmp/Preprocessing/avg10_split300/'

# ã€å¯¹åº”è„šæœ¬ã€‘data_path_name
DATA_PATH_NAME = 'Arrival'


# =========================================================

class Args:
    def __init__(self):
        # --- åŸºç¡€é…ç½® (å¯¹åº” Shell è„šæœ¬) ---
        self.model_id = 'Flight_Batch_Eval'  # å ä½ç¬¦ï¼Œä¼šè¢«è¦†ç›–
        self.model = 'iTransformer'  # ã€å¯¹åº”è„šæœ¬ã€‘model_name
        self.data = 'trajectory'  # ã€å¯¹åº”è„šæœ¬ã€‘data="trajectory"
        self.features = 'M'  # ã€å¯¹åº”è„šæœ¬ã€‘features="M"
        self.task_name = 'long_term_forecast'

        # --- è·¯å¾„é…ç½® ---
        self.root_path = DATA_ROOT_PATH
        self.data_path = DATA_PATH_NAME

        # --- ç»´åº¦å®šä¹‰ (å¯¹åº” Shell è„šæœ¬) ---
        self.enc_in = 8  # ã€å¯¹åº”è„šæœ¬ã€‘enc_in_dim
        self.dec_in = 8  # ã€å¯¹åº”è„šæœ¬ã€‘dec_in_dim
        self.c_out = 8  # ã€å¯¹åº”è„šæœ¬ã€‘c_out_dim

        # --- åºåˆ—å‚æ•° (é»˜è®¤å€¼ï¼Œä¼šè¢«æ­£åˆ™è§£æè¦†ç›–) ---
        self.seq_len = 96
        self.label_len = 48
        self.pred_len = 24  # é»˜è®¤å€¼

        # --- æ¨¡å‹ç»“æ„å‚æ•° (å¯¹åº” Shell è„šæœ¬) ---
        self.d_model = 512  # é»˜è®¤å€¼ï¼Œè„šæœ¬ä¸­æœªæ˜¾å¼æŒ‡å®šï¼Œé€šå¸¸ä¸º512
        self.n_heads = 8  # é»˜è®¤å€¼
        self.e_layers = 2  # ã€å¯¹åº”è„šæœ¬ã€‘e_layers=2
        self.d_layers = 0  # ã€å¯¹åº”è„šæœ¬ã€‘d_layers=0
        self.d_ff = 2048  # é»˜è®¤å€¼
        self.factor = 3  # ã€å¯¹åº”è„šæœ¬ã€‘factor=3
        self.dropout = 0.1
        self.embed = 'timeF'
        self.activation = 'gelu'
        self.output_attention = False

        # --- è¿è¡Œå‚æ•° ---
        self.num_workers = 0  # æ¨ç†æ—¶å»ºè®®è®¾ä¸º0ï¼Œé¿å…å¤šè¿›ç¨‹æŠ¥é”™
        self.itr = 1
        self.batch_size = 512  # ã€å¯¹åº”è„šæœ¬ã€‘batch_size
        self.freq = 'h'  # <--- å¿…é¡»åŠ ä¸Šè¿™ä¸€è¡Œ (å¯ä»¥æ˜¯ 'h', 't', 's' ç­‰ï¼Œé€šå¸¸ 'h' é€šç”¨)
        self.target = 'OT'  # [æ–°å¢] é¢„æµ‹ç›®æ ‡åˆ—åï¼Œè™½ç„¶å¤šå˜é‡é¢„æµ‹ä¸ç”¨ï¼Œä½†Datasetåˆå§‹åŒ–å¯èƒ½éœ€è¦
        self.seasonal_patterns = 'Monthly'
        self.use_amp = False
        self.distil = True
        self.moving_avg = 25
        self.patch_len = 16

        self.use_gpu = True
        self.gpu = 0
        self.gpu_type = 'cuda'
        self.use_multi_gpu = False
        self.devices = '0'

        self.p_hidden_dims = [128, 128]
        self.p_hidden_layers = 2

        # --- å…³é”®æ§åˆ¶å‚æ•° ---
        self.is_training = 0  # å¼ºåˆ¶ä¸ºæµ‹è¯•æ¨¡å¼
        self.inverse = True  # å¼€å¯åå½’ä¸€åŒ–ï¼Œç¡®ä¿å¾—åˆ°ç‰©ç†å€¼
        self.use_dtw = False  # æ˜¯å¦è®¡ç®—DTW


# æ£€æŸ¥ Checkpoint è·¯å¾„
if not os.path.exists(CHECKPOINT_ROOT):
    print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° Checkpoint è·¯å¾„ {CHECKPOINT_ROOT}")
    print("è¯·æ£€æŸ¥ä»£ç ä¸­ CHECKPOINT_ROOT å˜é‡æ˜¯å¦é…ç½®æ­£ç¡®ã€‚")
    sys.exit(1)

# è·å–æ‰€æœ‰å­æ–‡ä»¶å¤¹
subfolders = os.listdir(CHECKPOINT_ROOT)
subfolders.sort()

print(f"ğŸ“‚ åœ¨ {CHECKPOINT_ROOT} å‘ç° {len(subfolders)} ä¸ªå®éªŒæ–‡ä»¶å¤¹")
print("ğŸš€ å¼€å§‹æ‰¹é‡è¯„ä¼°...\n")

# å‡†å¤‡å†™å…¥ç»“æœçš„æ–‡ä»¶
output_file = "result_long_term_forecast.txt"

for folder_name in subfolders:
    full_folder_path = os.path.join(CHECKPOINT_ROOT, folder_name)

    # å¿½ç•¥éæ–‡ä»¶å¤¹
    if not os.path.isdir(full_folder_path):
        continue

    # è¿‡æ»¤ï¼šåªå¤„ç†åŒ…å«æ‚¨æ•°æ®è·¯å¾„å(Arrival)æˆ–æ¨¡å‹å(iTransformer)çš„æ–‡ä»¶å¤¹
    if "iTransformer" not in folder_name:
        continue

    # =========================================================
    #  2. æ­£åˆ™è¡¨è¾¾å¼è§£æå‚æ•° (ä»æ–‡ä»¶å¤¹ååæ¨å‚æ•°)
    # =========================================================
    try:
        args = Args()

        # 1. æå–åºåˆ—é•¿åº¦ (sl), æ ‡ç­¾é•¿åº¦ (ll), é¢„æµ‹é•¿åº¦ (pl)
        # æ–‡ä»¶å¤¹åç¤ºä¾‹: ..._sl96_ll48_pl24_...
        sl_match = re.search(r'sl(\d+)', folder_name)
        ll_match = re.search(r'll(\d+)', folder_name)
        pl_match = re.search(r'pl(\d+)', folder_name)

        if sl_match: args.seq_len = int(sl_match.group(1))
        if ll_match: args.label_len = int(ll_match.group(1))
        if pl_match: args.pred_len = int(pl_match.group(1))

        # 2. æå–æ¨¡å‹å‚æ•° (dm, nh, el, dl, df, fc)
        dm_match = re.search(r'dm(\d+)', folder_name)
        nh_match = re.search(r'nh(\d+)', folder_name)
        el_match = re.search(r'el(\d+)', folder_name)
        dl_match = re.search(r'dl(\d+)', folder_name)
        df_match = re.search(r'df(\d+)', folder_name)
        fc_match = re.search(r'fc(\d+)', folder_name)

        if dm_match: args.d_model = int(dm_match.group(1))
        if nh_match: args.n_heads = int(nh_match.group(1))
        if el_match: args.e_layers = int(el_match.group(1))
        if dl_match: args.d_layers = int(dl_match.group(1))
        if df_match: args.d_ff = int(df_match.group(1))
        if fc_match: args.factor = int(fc_match.group(1))

        print(f"\n>>> æ­£åœ¨è¯„ä¼°: iTransformer, Pred={args.pred_len}")
        print(f"    Folder: {folder_name}")
        print(f"    Structure: el{args.e_layers}-dl{args.d_layers}-dmodel{args.d_model}")

    except Exception as e:
        print(f"âš ï¸ è§£ææ–‡ä»¶å¤¹ {folder_name} å‚æ•°å¤±è´¥, ä½¿ç”¨é»˜è®¤å‚æ•°. é”™è¯¯: {e}")
        # ç»§ç»­å°è¯•è¿è¡Œï¼Œä½¿ç”¨é»˜è®¤ Args

    # =========================================================
    #  3. åŠ è½½æƒé‡å¹¶è¿è¡Œ
    # =========================================================

    checkpoint_path = os.path.join(full_folder_path, 'checkpoint.pth')
    if not os.path.exists(checkpoint_path):
        print(f"   âš ï¸ è·³è¿‡ï¼šæœªæ‰¾åˆ° checkpoint.pth")
        continue

    try:
        # åˆå§‹åŒ–å®éªŒ
        exp = Exp_Long_Term_Forecast(args)

        # æ‰‹åŠ¨åŠ è½½æƒé‡
        print(f"   Loading weights...")
        exp.model.load_state_dict(torch.load(checkpoint_path))

        # è¿è¡Œæµ‹è¯•
        # setting å‚æ•°ä»…ç”¨äºæ—¥å¿—è®°å½•åå­—
        exp.test(setting=folder_name, test=0)

    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()

print(f"\nâœ… å…¨éƒ¨å®Œæˆï¼è¯·æŸ¥çœ‹æ ¹ç›®å½•ä¸‹çš„ {output_file}")